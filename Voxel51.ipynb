{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pzz0D_RZ7yA"
      },
      "source": [
        "Goal: We want to be able to visualize what points each batch selection method is choosing at each part of the training process of a model.\n",
        "\n",
        "Label each point with the following - loss value, batch #, if included in selection method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI2LQi_VOMXB"
      },
      "source": [
        "# Set Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Iw3ldY_RMdF"
      },
      "source": [
        "#### Install dependencies and load pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0_7gNm7DOK8D",
        "outputId": "de8b1ec0-be9b-477d-9e1a-97575bf1bbc7"
      },
      "outputs": [],
      "source": [
        "import fiftyone.zoo as foz\n",
        "import cv2\n",
        "import numpy as np\n",
        "import fiftyone.brain as fob\n",
        "from fiftyone import ViewField as F\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import models\n",
        "import yaml\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import fiftyone as fo # Import fiftyone\n",
        "from PIL import Image # Import Image\n",
        "import detectors\n",
        "import timm\n",
        "from methods.DivBS import DivBS\n",
        "from methods.Uniform import Uniform\n",
        "from methods.Bayesian import Bayesian\n",
        "from methods.TrainLoss import TrainLoss\n",
        "from methods.RhoLoss import RhoLoss\n",
        "from utils import custom_logger\n",
        "\n",
        "# resnet18_cifar10 = timm.create_model(\"resnet18_cifar10\", pretrained=True)\n",
        "# resnet34_cifar10 = timm.create_model(\"resnet34_cifar10\", pretrained=True)\n",
        "# resnet50_cifar10 = timm.create_model(\"resnet50_cifar10\", pretrained=True)\n",
        "# resnet34_supcon_cifar10 = timm.create_model(\"resnet34_supcon_cifar10\", pretrained=True)\n",
        "resnet50_supcon_cifar10 = timm.create_model(\"resnet50_supcon_cifar10\", pretrained=True)\n",
        "#resnet50_simclr_cifar10 = timm.create_model(\"resnet50_simclr_cifar10\", pretrained=True)\n",
        "pretrained_models = {\n",
        "    # \"resnet18_cifar10\": resnet18_cifar10,\n",
        "    # \"resnet34_cifar10\": resnet34_cifar10,\n",
        "    # \"resnet50_cifar10\": resnet50_cifar10,\n",
        "    # \"resnet34_supcon_cifar10\": resnet34_supcon_cifar10,\n",
        "    \"resnet50_supcon_cifar10\": resnet50_supcon_cifar10,\n",
        "    #\"resnet50_simclr_cifar10\": resnet50_simclr_cifar10\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G41odTNh8iqP"
      },
      "source": [
        "#### Set up consistent dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAP92qAN6GQU",
        "outputId": "f5d4557d-5891-42a9-d7b4-1105e3bea3c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split 'test' already downloaded\n",
            "Loading existing dataset 'cifar10-test'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
          ]
        }
      ],
      "source": [
        "# Define the FiftyOneCIFARDataset class (copied from cell_id: -zonHH4HkINl)\n",
        "class FiftyOneCIFARDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, fiftyone_dataset, class_to_idx, transform=None):\n",
        "        self.dataset = fiftyone_dataset\n",
        "        self.transform = transform\n",
        "        self.sample_ids = list(self.dataset.values(\"_id\"))  # List of sample IDs\n",
        "        self.class_to_idx = class_to_idx # Store the class_to_idx mapping\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sample_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample_id = self.sample_ids[idx]\n",
        "        sample = self.dataset[sample_id]  # Access by sample ID\n",
        "        img = Image.open(sample.filepath).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        # Convert string label to integer index using the mapping\n",
        "        label_str = sample.ground_truth.label\n",
        "        label_int = self.class_to_idx[label_str]\n",
        "        label_tensor = torch.tensor(label_int, dtype=torch.long) # Ensure label is a LongTensor\n",
        "\n",
        "        return img, label_tensor, str(sample_id)  # Return tensor label and sample_id as string\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Use train_dataset to get class_to_idx function\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "class_to_idx = train_dataset.class_to_idx\n",
        "\n",
        "# Instantiate the original Fiftyone dataset, custum FiftyOne dataset, and dataloader\n",
        "fo_dataset = foz.load_zoo_dataset(\"cifar10\", split=\"test\")\n",
        "custom_fiftyone_dataset = FiftyOneCIFARDataset(fo_dataset, class_to_idx=class_to_idx, transform=transform)\n",
        "custom_fiftyone_dataloader = DataLoader(custom_fiftyone_dataset, batch_size=64, shuffle=False) # Use shuffle=False for consistent batching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSdtZppARHTo"
      },
      "source": [
        "#### Set up ResNet model checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8HnVuk78RFyJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read config file\n",
        "config_file = \"cfg/cifar10.yaml\"\n",
        "with open(config_file, 'r') as f:\n",
        "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
        "        f.close()\n",
        "\n",
        "model_type = config['networks']['type']\n",
        "model_args = config['networks']['params']\n",
        "empty_model = getattr(models, model_type)(**model_args)\n",
        "\n",
        "checkpoints = ['visualization_checkpoints/checkpoint_epoch_' + str(checkpoint) + '.pth.tar' for checkpoint in [3, 5, 7]] # or range(0, 200, 25)\n",
        "model_params = torch.load(checkpoints[0], map_location=torch.device('cpu'), weights_only=False)\n",
        "empty_model.load_state_dict(model_params['state_dict'])\n",
        "\n",
        "# Temporary to make everything run faster\n",
        "# first_checkpoint = checkpoints[0]\n",
        "# last_checkpoint = checkpoints[-1]\n",
        "# checkpoints = [first_checkpoint, last_checkpoint]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3rkwE7BkLSW"
      },
      "source": [
        "#### FiftyOne Analysis Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "sXUxxHnSlXlK"
      },
      "outputs": [],
      "source": [
        "def prepare_embeddings(model, model_name, fo_dataset):\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    batch_size = 128\n",
        "    embeddings = []\n",
        "\n",
        "    # Resize, normalize, and convert images to (C, H, W)\n",
        "    target_size = (32, 32)  # required input size for the CNN\n",
        "\n",
        "    image_tensors = []\n",
        "    for f in fo_dataset.values(\"filepath\"):\n",
        "        img = cv2.imread(f, cv2.IMREAD_COLOR)  # force 3-channel BGR\n",
        "        img = cv2.resize(img, target_size)\n",
        "        img = img.astype(np.float32) / 255.0  # normalize to [0,1]\n",
        "        img = img.transpose(2, 0, 1)  # convert from (H, W, C) to (C, H, W)\n",
        "        image_tensors.append(img)\n",
        "\n",
        "    for i in range(0, len(image_tensors), batch_size):\n",
        "        batch_np = np.stack(image_tensors[i:i+batch_size])\n",
        "        batch_tensor = torch.tensor(batch_np)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out = model(batch_tensor)\n",
        "            embeddings.append(out.cpu().numpy())\n",
        "\n",
        "    embedding_outputs = np.concatenate(embeddings, axis=0)\n",
        "\n",
        "    results = fob.compute_visualization(\n",
        "        fo_dataset,\n",
        "        embeddings=embedding_outputs,\n",
        "        num_dims=2,\n",
        "        method=\"umap\",\n",
        "        brain_key=model_name+\"_test\",\n",
        "        verbose=True,\n",
        "        seed=51,\n",
        "    )\n",
        "    fo_dataset.load_brain_results(model_name+\"_test\")\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating visualization...\n",
            "UMAP(n_jobs=1, random_state=51, verbose=True)\n",
            "Thu Oct  2 13:48:08 2025 Construct fuzzy simplicial set\n",
            "Thu Oct  2 13:48:08 2025 Finding Nearest Neighbors\n",
            "Thu Oct  2 13:48:08 2025 Building RP forest with 10 trees\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/phancock/Online-Batch-Selection/.venv/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Oct  2 13:48:08 2025 NN descent for 13 iterations\n",
            "\t 1  /  13\n",
            "\t 2  /  13\n",
            "\t 3  /  13\n",
            "\t 4  /  13\n",
            "\tStopping threshold met -- exiting after 4 iterations\n",
            "Thu Oct  2 13:48:10 2025 Finished Nearest Neighbor Search\n",
            "Thu Oct  2 13:48:10 2025 Construct embedding\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:   1%|            6/500 [00:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  0  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  11%| █▏         57/500 [00:01]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  50  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  21%| ██▏        107/500 [00:02]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  100  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  31%| ███▏       157/500 [00:03]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  150  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  41%| ████▏      207/500 [00:04]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  200  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  51%| █████▏     257/500 [00:05]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  250  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  61%| ██████▏    307/500 [00:07]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  300  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  71%| ███████▏   357/500 [00:08]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  350  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  81%| ████████▏  407/500 [00:09]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  400  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  91%| █████████▏ 457/500 [00:10]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  450  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed: 100%| ██████████ 500/500 [00:11]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Oct  2 13:48:22 2025 Finished embedding\n"
          ]
        }
      ],
      "source": [
        "## Optional to reset FiftyOne database\n",
        "# fo_dataset.delete()\n",
        "\n",
        "# Load embeddings for each model\n",
        "for model_name, model in pretrained_models.items():\n",
        "    prepare_embeddings(model, model_name, fo_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMXjCVba1vg6"
      },
      "source": [
        "# Add tags to dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Tag batch numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tag_batches(fo_dataset, custom_dataset, fo_dataloader):\n",
        "    if not fo_dataset.has_field(\"batch_num\"):\n",
        "        fo_dataset.add_sample_field(\"batch_num\", fo.IntField)\n",
        "\n",
        "    sample_ids = custom_dataset.sample_ids\n",
        "    batch_size = fo_dataloader.batch_size\n",
        "\n",
        "    for i, sample_id in enumerate(sample_ids):\n",
        "        batch_index = i // batch_size\n",
        "        sample = fo_dataset[sample_id]\n",
        "        sample[\"batch_num\"] = batch_index\n",
        "        sample.save()  # <-- Save each modified sample\n",
        "\n",
        "tag_batches(fo_dataset, custom_fiftyone_dataset, custom_fiftyone_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Tag class probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tag class probabilities to each sample in the fiftyone dataset\n",
        "def tag_class_probabilities(checkpoints, fo_dataset, custom_dataset):\n",
        "    \n",
        "    image_tensors = []\n",
        "    for f in fo_dataset.values(\"filepath\"):\n",
        "        img = cv2.imread(f, cv2.IMREAD_COLOR)  # force 3-channel BGR\n",
        "        img = cv2.resize(img, (32, 32))\n",
        "        img = img.astype(np.float32) / 255.0  # normalize to [0,1]\n",
        "        img = img.transpose(2, 0, 1)  # convert from (H, W, C) to (C, H, W)\n",
        "        image_tensors.append(img)\n",
        "\n",
        "    for checkpoint in checkpoints:\n",
        "        # Load model from checkpoint\n",
        "        model = empty_model\n",
        "        model.load_state_dict(torch.load(checkpoint, map_location=torch.device('cpu'), weights_only=False)['state_dict'])\n",
        "\n",
        "        # Get outputs and probabilities\n",
        "        output = model(torch.tensor(image_tensors))\n",
        "        probabilities = nn.Softmax(dim=1)(output) # or nn.LogSoftmax(dim=1)(output)\n",
        "        epoch = checkpoint.split('_')[-1].split('.')[0]\n",
        "        sample_ids = custom_dataset.sample_ids\n",
        "\n",
        "        for i, sample_id in enumerate(sample_ids):\n",
        "            sample = fo_dataset[sample_id]\n",
        "            for class_index in range(10):\n",
        "                sample[f\"epoch_{epoch}_class_{class_index}_prob\"] = float(probabilities[i, class_index].item())\n",
        "            sample.save()  # <-- Save each modified sample\n",
        "\n",
        "# Tag probabilities for each class\n",
        "tag_class_probabilities(checkpoints, fo_dataset, custom_fiftyone_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C3K9h0R35Ck"
      },
      "source": [
        "#### Tag loss values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TlVbVdQPOX5p"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_3.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_3.pth.tar\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_5.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_5.pth.tar\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_7.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_7.pth.tar\n"
          ]
        }
      ],
      "source": [
        "# Might be wrong since the torch cifar10 dataset and fiftyone cifar10 dataset might differ in the ordering which would result in incorrect tagging\n",
        "\n",
        "def tag_losses(checkpoints, dataset, dataloader):\n",
        "    for checkpoint in checkpoints:\n",
        "        model = empty_model\n",
        "        print(f\"Loading model from path: {checkpoint}\") # Added print statement\n",
        "        # Load the model state dictionary, ensuring map_location is set if needed (e.g., if trained on GPU and loading on CPU)\n",
        "        try: # Added try-except block for loading model\n",
        "            model.load_state_dict(torch.load(checkpoint, map_location=torch.device('cpu'), weights_only=False)['state_dict'])\n",
        "            print(f\"Successfully loaded model from {checkpoint}\") # Added print statement\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model from {checkpoint}: {e}\")\n",
        "            continue # Skip to the next checkpoint if loading fails\n",
        "        \n",
        "        checkpoint_num = checkpoint.split('_')[-1].split('.')[0]\n",
        "        model_name = f'model_epoch_{checkpoint_num}'\n",
        "        criterion_none = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "        losses_by_id = {}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels, sample_ids in dataloader:\n",
        "                outputs = model(inputs)\n",
        "                individual_losses = criterion_none(outputs, labels)\n",
        "\n",
        "                for i, sample_id in enumerate(sample_ids):\n",
        "                    losses_by_id[sample_id] = round(individual_losses[i].item(), 4)\n",
        "\n",
        "        # Ensure the 'losses' field exists only once\n",
        "        if not dataset.has_field(\"losses\"):\n",
        "            dataset.add_sample_field(\"losses\", fo.DictField)\n",
        "\n",
        "        for sample_id, loss in losses_by_id.items():\n",
        "            sample = dataset[sample_id]\n",
        "            if sample.losses is None:\n",
        "                sample.losses = {}\n",
        "            sample.losses[model_name] = loss\n",
        "            sample[model_name + \"_loss\"] = loss\n",
        "            sample.save()\n",
        "\n",
        "# Call the tag_data function with the dataloader, dataset, criterion, and checkpoint paths\n",
        "tag_losses(checkpoints, fo_dataset, custom_fiftyone_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXoIuIvSlKZ_"
      },
      "source": [
        "#### Tag method selected points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rNvwCPcfPNei",
        "outputId": "2a3b6145-92ce-4d6a-9309-544cb60ad3ce"
      },
      "outputs": [],
      "source": [
        "class BaseSelectionMixin:\n",
        "    \"\"\"Mixin providing the get_indices method for any selector.\"\"\"\n",
        "    def get_indices(self, dataset, epoch, batch_size=64):\n",
        "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "        all_indexes = []\n",
        "\n",
        "        for i, datas in enumerate(data_loader):\n",
        "            inputs = datas[0]\n",
        "            targets = datas[1]\n",
        "            indexes = np.arange(len(inputs))\n",
        "\n",
        "            # Call batch selection logic\n",
        "            inputs, targets, indexes = self.before_batch(i, inputs, targets, indexes, epoch)\n",
        "            all_indexes.append(indexes)\n",
        "\n",
        "        return all_indexes\n",
        "\n",
        "\n",
        "class Uniform_Selection(BaseSelectionMixin, Uniform):\n",
        "    pass\n",
        "\n",
        "\n",
        "class DivBS_Selection(BaseSelectionMixin, DivBS):\n",
        "    pass\n",
        "\n",
        "\n",
        "class TrainLoss_Selection(BaseSelectionMixin, TrainLoss):\n",
        "    pass\n",
        "\n",
        "\n",
        "class RhoLoss_Selection(BaseSelectionMixin, RhoLoss):\n",
        "    pass\n",
        "\n",
        "class Bayesian_Selection(Bayesian):\n",
        "    def get_indices(self, dataset, epoch):\n",
        "\n",
        "        data_loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "        all_indexes = []\n",
        "\n",
        "        for i, datas in enumerate(data_loader):\n",
        "            inputs = datas[0]\n",
        "            targets = datas[1]\n",
        "            indexes = np.arange(inputs.shape[0])\n",
        "\n",
        "            # Call batch selection logic\n",
        "            inputs, targets, indexes = self.before_batch(i, inputs, targets, indexes, epoch)\n",
        "            all_indexes.append(indexes)\n",
        "\n",
        "        return all_indexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": true,
        "id": "ND2KeCoLMXZH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cuda\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_3.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_3.pth.tar\n",
            "Creating DivBS...\n",
            "balance: False\n",
            "selecting samples for epoch 3, ratio 0.1\n",
            "Creating Uniform...\n",
            "selecting samples for epoch 3\n",
            "balance: False\n",
            "ratio: 0.1\n",
            "Creating TrainLoss...\n",
            "balance: False\n",
            "selecting samples for epoch 3, ratio 0.1\n",
            "Creating RhoLoss...\n",
            "Loading holdout model from /home/phancock/Online-Batch-Selection/exp/test_rholoss/RhoLoss/best_holdout.pth.tar\n",
            "Cached irreducible losses for 50000 samples in dataset.\n",
            "balance: False\n",
            "selecting samples for epoch 3, ratio 0.1\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_5.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_5.pth.tar\n",
            "Creating DivBS...\n",
            "balance: False\n",
            "selecting samples for epoch 5, ratio 0.1\n",
            "Creating Uniform...\n",
            "selecting samples for epoch 5\n",
            "balance: False\n",
            "ratio: 0.1\n",
            "Creating TrainLoss...\n",
            "balance: False\n",
            "selecting samples for epoch 5, ratio 0.1\n",
            "Creating RhoLoss...\n",
            "Loading holdout model from /home/phancock/Online-Batch-Selection/exp/test_rholoss/RhoLoss/best_holdout.pth.tar\n",
            "Cached irreducible losses for 50000 samples in dataset.\n",
            "balance: False\n",
            "selecting samples for epoch 5, ratio 0.1\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_7.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_7.pth.tar\n",
            "Creating DivBS...\n",
            "balance: False\n",
            "selecting samples for epoch 7, ratio 0.1\n",
            "Creating Uniform...\n",
            "selecting samples for epoch 7\n",
            "balance: False\n",
            "ratio: 0.1\n",
            "Creating TrainLoss...\n",
            "balance: False\n",
            "selecting samples for epoch 7, ratio 0.1\n",
            "Creating RhoLoss...\n",
            "Loading holdout model from /home/phancock/Online-Batch-Selection/exp/test_rholoss/RhoLoss/best_holdout.pth.tar\n",
            "Cached irreducible losses for 50000 samples in dataset.\n",
            "balance: False\n",
            "selecting samples for epoch 7, ratio 0.1\n"
          ]
        }
      ],
      "source": [
        "# Set up logger\n",
        "try: # Added try-except block for setting up logger\n",
        "    logger = custom_logger(\"./exp\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    logger.info('device: ' + str(device))\n",
        "except Exception as e:\n",
        "    print(f\"Error setting up logger: {e}\")\n",
        "\n",
        "selected_points = {}\n",
        "methods = ['DivBS', 'Uniform', 'TrainLoss', 'RhoLoss'] #'Bayesian']\n",
        "\n",
        "for method in methods:\n",
        "    selected_points[method] = []\n",
        "\n",
        "selector_classes = {\n",
        "    \"DivBS\": DivBS_Selection,\n",
        "    \"Uniform\": Uniform_Selection,\n",
        "    \"TrainLoss\": TrainLoss_Selection,\n",
        "    \"RhoLoss\": RhoLoss_Selection,\n",
        "    #\"Bayesian\": Bayesian_Selection,\n",
        "}\n",
        "\n",
        "# NOTE: Can't start at checkpoint 0 because it raises an error with feature tensor becoming 0\n",
        "for checkpoint in checkpoints:\n",
        "\n",
        "    model = empty_model\n",
        "    print(f\"Loading model from path: {checkpoint}\") \n",
        "\n",
        "    try: # try-except block for loading model\n",
        "        model.load_state_dict(torch.load(checkpoint, map_location=torch.device('cpu'), weights_only=False)['state_dict'])\n",
        "        print(f\"Successfully loaded model from {checkpoint}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model from {checkpoint}: {e}\")\n",
        "        continue # Skip to the next checkpoint if loading fails\n",
        "    \n",
        "    checkpoint_num = int(checkpoint.split('_')[-1].split('.')[0])\n",
        "    # Create and run selectors\n",
        "    for method, cls in selector_classes.items():\n",
        "        selector = cls(config, logger)\n",
        "        selector.model = model\n",
        "        \n",
        "        run_indices = selector.get_indices(custom_fiftyone_dataset, checkpoint_num)\n",
        "        selected_points[method].append(run_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "collapsed": true,
        "id": "TQ4BHjFoJlh1"
      },
      "outputs": [],
      "source": [
        "def tag_selected_points(checkpoints, fo_dataset, custom_dataset, dataloader, selected_points, method_name):\n",
        "    # Iterate over each checkpoint\n",
        "    for ckpt_idx, checkpoint in enumerate(checkpoints):\n",
        "        # Added try-except block for loading model\n",
        "        \n",
        "        checkpoint_num = checkpoint.split('_')[-1].split('.')[0]\n",
        "        model_name = f'model_epoch_{checkpoint_num}'\n",
        "\n",
        "        sample_ids = custom_dataset.sample_ids\n",
        "        batch_size = dataloader.batch_size\n",
        "\n",
        "        # Get selected indices for this checkpoint\n",
        "        batches_of_selected_points = selected_points[ckpt_idx]\n",
        "\n",
        "        for i, sample_id in enumerate(sample_ids):\n",
        "            sample_batch_index = i // batch_size\n",
        "            in_batch_index = i % batch_size\n",
        "\n",
        "            # Get selected indices for this batch\n",
        "            batch_selected_points = batches_of_selected_points[sample_batch_index]\n",
        "            # Normalize to list\n",
        "            if isinstance(batch_selected_points, np.ndarray):\n",
        "                batch_selected_points = batch_selected_points.tolist()\n",
        "            elif isinstance(batch_selected_points, (np.int64, int)):\n",
        "                batch_selected_points = [int(batch_selected_points)]\n",
        "\n",
        "            # Convert to set for faster lookup\n",
        "            batch_selected_points = set(batch_selected_points)\n",
        "\n",
        "            # if sample is in the selected points for this batch, tag it as True, else False\n",
        "            selected = in_batch_index in batch_selected_points\n",
        "            sample = fo_dataset[sample_id]\n",
        "            sample[model_name + \"_\" + method_name + \"_selected\"] = selected\n",
        "            sample.save()\n",
        "\n",
        "for method in methods:\n",
        "    tag_selected_points(checkpoints, fo_dataset, custom_fiftyone_dataset, custom_fiftyone_dataloader, selected_points[method], method)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhDWWzBUb4qR"
      },
      "source": [
        "# Show Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Potential Improvements:\n",
        "* Add linked plot for even better visualization (which plots would be best for that?)\n",
        "* Find way to include Bayesian selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([7, 8, 4,  ..., 4, 4, 4])\n",
            "tensor([5, 1, 5,  ..., 5, 1, 7])\n",
            "tensor([5, 1, 6,  ..., 5, 1, 7])\n"
          ]
        }
      ],
      "source": [
        "image_tensors = []\n",
        "for f in fo_dataset.values(\"filepath\"):\n",
        "    img = cv2.imread(f, cv2.IMREAD_COLOR)  # force 3-channel BGR\n",
        "    img = cv2.resize(img, (32, 32))\n",
        "    img = img.astype(np.float32) / 255.0  # normalize to [0,1]\n",
        "    img = img.transpose(2, 0, 1)  # convert from (H, W, C) to (C, H, W)\n",
        "    image_tensors.append(img)\n",
        "\n",
        "for checkpoint in checkpoints:\n",
        "    # Load model from checkpoint\n",
        "    model = empty_model\n",
        "    model.load_state_dict(torch.load(checkpoint, map_location=torch.device('cpu'), weights_only=False)['state_dict'])\n",
        "\n",
        "    # Get outputs and probabilities\n",
        "    output = model(torch.tensor(image_tensors))\n",
        "    probabilities = nn.Softmax(dim=1)(output) # or nn.LogSoftmax(dim=1)(output)\n",
        "    epoch = checkpoint.split('_')[-1].split('.')[0]\n",
        "    sample_ids = custom_fiftyone_dataset.sample_ids\n",
        "\n",
        "    print(probabilities.argmax(dim=1))\n",
        "\n",
        "    for i, sample_id in enumerate(sample_ids):\n",
        "        pred_class = int(probabilities.argmax(dim=1)[i].item())\n",
        "        sample = fo_dataset[sample_id]\n",
        "        # Store as a Classification label (which supports colors)\n",
        "        sample[f\"epoch_{epoch}_predictions\"] = fo.Classification(\n",
        "            label=str(pred_class),  # use string name or class id\n",
        "            confidence=float(probabilities[i][pred_class].item())\n",
        "        )\n",
        "        sample.save()\n",
        "        # sample[f\"epoch_{epoch}_predictions\"] = (probabilities.argmax(dim=1)[i].item())\n",
        "        # sample.save()  # <-- Save each modified sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import fiftyone as fo\n",
        "# from fiftyone.core.odm.dataset import ColorScheme\n",
        "# from fiftyone import Classification\n",
        "\n",
        "# # -----------------------------\n",
        "# # 1. Extract ground truth field\n",
        "# # -----------------------------\n",
        "# gt_scheme = fo_dataset.app_config.color_scheme\n",
        "# gt_field_cfg = None\n",
        "# for f in gt_scheme.fields:\n",
        "#     if f[\"path\"] == \"ground_truth\":\n",
        "#         gt_field_cfg = f\n",
        "#         break\n",
        "\n",
        "# if gt_field_cfg is None:\n",
        "#     raise ValueError(\"No color scheme found for 'ground_truth'!\")\n",
        "\n",
        "# # Auto-detect classes from ground truth\n",
        "# classes = [vc[\"value\"] for vc in gt_field_cfg[\"valueColors\"]]\n",
        "# string_to_color = {vc[\"value\"]: vc[\"color\"] for vc in gt_field_cfg[\"valueColors\"]}\n",
        "\n",
        "# # -----------------------------\n",
        "# # 2. Detect all numeric prediction fields\n",
        "# # -----------------------------\n",
        "\n",
        "# pred_fields = [\n",
        "#     f for f in fo_dataset.get_field_schema().keys()\n",
        "#     if f.startswith(\"epoch_\") and f.endswith(\"_predictions\")\n",
        "# ]\n",
        "\n",
        "# # -----------------------------\n",
        "# # 3. Create color scheme for predictions\n",
        "# # -----------------------------\n",
        "# pred_value_colors = []\n",
        "# for c in classes:\n",
        "#     color = string_to_color.get(c, \"#000000\")  # default to black if not found\n",
        "#     pred_value_colors.append({\"value\": c, \"color\": color})\n",
        "# pred_scheme = ColorScheme(fields=[{\n",
        "#     \"path\": f,\n",
        "#     \"type\": \"classification\",\n",
        "#     \"valueColors\": pred_value_colors\n",
        "# } for f in pred_fields])  \n",
        "\n",
        "# fo.app_config.color_scheme = pred_scheme\n",
        "# fo.app_config.color_by = \"value\"\n",
        "# fo.app_config.field \n",
        "\n",
        "# # Show fiftyone app\n",
        "# session = fo.launch_app(fo_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"800\"\n",
              "            src=\"http://localhost:5151/?notebook=True&subscription=11bd8052-9625-4682-8b07-835f9efe491f\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x71fe291593c0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "session = fo.launch_app(fo_dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "v3rkwE7BkLSW",
        "2C3K9h0R35Ck"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "online-bs",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
