{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pzz0D_RZ7yA"
      },
      "source": [
        "Goal: We want to be able to visualize what points each batch selection method is choosing at each part of the training process of a model.\n",
        "\n",
        "Label each point with the following - loss value, batch #, if included in selection method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI2LQi_VOMXB"
      },
      "source": [
        "# Set Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Iw3ldY_RMdF"
      },
      "source": [
        "#### Install dependencies and load pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0_7gNm7DOK8D",
        "outputId": "de8b1ec0-be9b-477d-9e1a-97575bf1bbc7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/phancock/Online-Batch-Selection/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/home/phancock/Online-Batch-Selection/.venv/lib/python3.10/site-packages/outdated/__init__.py:36: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import parse_version\n"
          ]
        }
      ],
      "source": [
        "import fiftyone.zoo as foz\n",
        "import cv2\n",
        "import numpy as np\n",
        "import fiftyone.brain as fob\n",
        "from fiftyone import ViewField as F\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import models\n",
        "import yaml\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import fiftyone as fo # Import fiftyone\n",
        "from PIL import Image # Import Image\n",
        "import detectors\n",
        "import timm\n",
        "from methods.DivBS import DivBS\n",
        "from methods.Uniform import Uniform\n",
        "from methods.Bayesian import Bayesian\n",
        "from methods.TrainLoss import TrainLoss\n",
        "from methods.RhoLoss import RhoLoss\n",
        "from utils import custom_logger\n",
        "\n",
        "# resnet18_cifar10 = timm.create_model(\"resnet18_cifar10\", pretrained=True)\n",
        "# resnet34_cifar10 = timm.create_model(\"resnet34_cifar10\", pretrained=True)\n",
        "# resnet50_cifar10 = timm.create_model(\"resnet50_cifar10\", pretrained=True)\n",
        "# resnet34_supcon_cifar10 = timm.create_model(\"resnet34_supcon_cifar10\", pretrained=True)\n",
        "resnet50_supcon_cifar10 = timm.create_model(\"resnet50_supcon_cifar10\", pretrained=True)\n",
        "#resnet50_simclr_cifar10 = timm.create_model(\"resnet50_simclr_cifar10\", pretrained=True)\n",
        "pretrained_models = {\n",
        "    # \"resnet18_cifar10\": resnet18_cifar10,\n",
        "    # \"resnet34_cifar10\": resnet34_cifar10,\n",
        "    # \"resnet50_cifar10\": resnet50_cifar10,\n",
        "    # \"resnet34_supcon_cifar10\": resnet34_supcon_cifar10,\n",
        "    \"resnet50_supcon_cifar10\": resnet50_supcon_cifar10,\n",
        "    #\"resnet50_simclr_cifar10\": resnet50_simclr_cifar10\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G41odTNh8iqP"
      },
      "source": [
        "#### Set up consistent dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAP92qAN6GQU",
        "outputId": "f5d4557d-5891-42a9-d7b4-1105e3bea3c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split 'test' already downloaded\n",
            "Loading 'cifar10' split 'test'\n",
            " 100% |█████████████| 10000/10000 [5.3s elapsed, 0s remaining, 1.9K samples/s]      \n",
            "Dataset 'cifar10-test' created\n"
          ]
        }
      ],
      "source": [
        "# Define the FiftyOneCIFARDataset class (copied from cell_id: -zonHH4HkINl)\n",
        "class FiftyOneCIFARDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, fiftyone_dataset, class_to_idx, transform=None):\n",
        "        self.dataset = fiftyone_dataset\n",
        "        self.transform = transform\n",
        "        self.sample_ids = list(self.dataset.values(\"_id\"))  # List of sample IDs\n",
        "        self.class_to_idx = class_to_idx # Store the class_to_idx mapping\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sample_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample_id = self.sample_ids[idx]\n",
        "        sample = self.dataset[sample_id]  # Access by sample ID\n",
        "        img = Image.open(sample.filepath).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        # Convert string label to integer index using the mapping\n",
        "        label_str = sample.ground_truth.label\n",
        "        label_int = self.class_to_idx[label_str]\n",
        "        label_tensor = torch.tensor(label_int, dtype=torch.long) # Ensure label is a LongTensor\n",
        "\n",
        "        return img, label_tensor, str(sample_id)  # Return tensor label and sample_id as string\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Use train_dataset to get class_to_idx function\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "class_to_idx = train_dataset.class_to_idx\n",
        "\n",
        "# Instantiate the original Fiftyone dataset, custum FiftyOne dataset, and dataloader\n",
        "fo_dataset = foz.load_zoo_dataset(\"cifar10\", split=\"test\")\n",
        "custom_fiftyone_dataset = FiftyOneCIFARDataset(fo_dataset, class_to_idx=class_to_idx, transform=transform)\n",
        "custom_fiftyone_dataloader = DataLoader(custom_fiftyone_dataset, batch_size=64, shuffle=False) # Use shuffle=False for consistent batching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSdtZppARHTo"
      },
      "source": [
        "#### Set up ResNet model checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8HnVuk78RFyJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read config file\n",
        "config_file = \"cfg/cifar10.yaml\"\n",
        "with open(config_file, 'r') as f:\n",
        "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
        "        f.close()\n",
        "\n",
        "model_type = config['networks']['type']\n",
        "model_args = config['networks']['params']\n",
        "empty_model = getattr(models, model_type)(**model_args)\n",
        "\n",
        "checkpoints = ['visualization_checkpoints/checkpoint_epoch_' + str(checkpoint) + '.pth.tar' for checkpoint in range(0,200,25)]\n",
        "model_params = torch.load(checkpoints[0], map_location=torch.device('cpu'), weights_only=False)\n",
        "empty_model.load_state_dict(model_params['state_dict'])\n",
        "\n",
        "# Temporary to make everything run faster\n",
        "# first_checkpoint = checkpoints[0]\n",
        "# last_checkpoint = checkpoints[-1]\n",
        "# checkpoints = [first_checkpoint, last_checkpoint]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3rkwE7BkLSW"
      },
      "source": [
        "#### FiftyOne Analysis Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "sXUxxHnSlXlK"
      },
      "outputs": [],
      "source": [
        "def prepare_embeddings(model, model_name, fo_dataset):\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    batch_size = 128\n",
        "    embeddings = []\n",
        "\n",
        "    # Resize, normalize, and convert images to (C, H, W)\n",
        "    target_size = (32, 32)  # required input size for the CNN\n",
        "\n",
        "    image_tensors = []\n",
        "    for f in fo_dataset.values(\"filepath\"):\n",
        "        img = cv2.imread(f, cv2.IMREAD_COLOR)  # force 3-channel BGR\n",
        "        img = cv2.resize(img, target_size)\n",
        "        img = img.astype(np.float32) / 255.0  # normalize to [0,1]\n",
        "        img = img.transpose(2, 0, 1)  # convert from (H, W, C) to (C, H, W)\n",
        "        image_tensors.append(img)\n",
        "\n",
        "    for i in range(0, len(image_tensors), batch_size):\n",
        "        batch_np = np.stack(image_tensors[i:i+batch_size])\n",
        "        batch_tensor = torch.tensor(batch_np)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out = model(batch_tensor)\n",
        "            embeddings.append(out.cpu().numpy())\n",
        "\n",
        "    embedding_outputs = np.concatenate(embeddings, axis=0)\n",
        "\n",
        "    results = fob.compute_visualization(\n",
        "        fo_dataset,\n",
        "        embeddings=embedding_outputs,\n",
        "        num_dims=2,\n",
        "        method=\"umap\",\n",
        "        brain_key=model_name+\"_test\",\n",
        "        verbose=True,\n",
        "        seed=51,\n",
        "    )\n",
        "    fo_dataset.load_brain_results(model_name+\"_test\")\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating visualization...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/phancock/Online-Batch-Selection/.venv/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UMAP(n_jobs=1, random_state=51, verbose=True)\n",
            "Fri Sep 26 15:44:46 2025 Construct fuzzy simplicial set\n",
            "Fri Sep 26 15:44:46 2025 Finding Nearest Neighbors\n",
            "Fri Sep 26 15:44:46 2025 Building RP forest with 10 trees\n",
            "Fri Sep 26 15:44:52 2025 NN descent for 13 iterations\n",
            "\t 1  /  13\n",
            "\t 2  /  13\n",
            "\t 3  /  13\n",
            "\t 4  /  13\n",
            "\tStopping threshold met -- exiting after 4 iterations\n",
            "Fri Sep 26 15:45:04 2025 Finished Nearest Neighbor Search\n",
            "Fri Sep 26 15:45:07 2025 Construct embedding\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:   2%| ▏          8/500 [00:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  0  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  12%| █▏         58/500 [00:01]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  50  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  22%| ██▏        108/500 [00:03]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  100  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  32%| ███▏       158/500 [00:04]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  150  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  42%| ████▏      208/500 [00:05]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  200  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  52%| █████▏     258/500 [00:06]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  250  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  62%| ██████▏    308/500 [00:07]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  300  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  72%| ███████▏   358/500 [00:08]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  350  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  82%| ████████▏  408/500 [00:09]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  400  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed:  92%| █████████▏ 458/500 [00:11]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  450  /  500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs completed: 100%| ██████████ 500/500 [00:12]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Sep 26 15:45:19 2025 Finished embedding\n"
          ]
        }
      ],
      "source": [
        "## Optional to reset FiftyOne database\n",
        "# fo_dataset.delete()\n",
        "\n",
        "# Load embeddings for each model\n",
        "for model_name, model in pretrained_models.items():\n",
        "    prepare_embeddings(model, model_name, fo_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMXjCVba1vg6"
      },
      "source": [
        "# Add tags to dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Tag batch numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tag_batches(fo_dataset, custom_dataset, fo_dataloader):\n",
        "    if not fo_dataset.has_field(\"batch_num\"):\n",
        "        fo_dataset.add_sample_field(\"batch_num\", fo.IntField)\n",
        "\n",
        "    sample_ids = custom_dataset.sample_ids\n",
        "    batch_size = fo_dataloader.batch_size\n",
        "\n",
        "    for i, sample_id in enumerate(sample_ids):\n",
        "        batch_index = i // batch_size\n",
        "        sample = fo_dataset[sample_id]\n",
        "        sample[\"batch_num\"] = batch_index\n",
        "        sample.save()  # <-- Save each modified sample\n",
        "\n",
        "tag_batches(fo_dataset, custom_fiftyone_dataset, custom_fiftyone_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Tag class probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3298494/1136682021.py:18: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  output = model(torch.tensor(image_tensors))\n"
          ]
        }
      ],
      "source": [
        "# Tag class probabilities to each sample in the fiftyone dataset\n",
        "def tag_class_probabilities(checkpoints, fo_dataset, custom_dataset):\n",
        "    \n",
        "    image_tensors = []\n",
        "    for f in fo_dataset.values(\"filepath\"):\n",
        "        img = cv2.imread(f, cv2.IMREAD_COLOR)  # force 3-channel BGR\n",
        "        img = cv2.resize(img, (32, 32))\n",
        "        img = img.astype(np.float32) / 255.0  # normalize to [0,1]\n",
        "        img = img.transpose(2, 0, 1)  # convert from (H, W, C) to (C, H, W)\n",
        "        image_tensors.append(img)\n",
        "\n",
        "    for checkpoint in checkpoints:\n",
        "        # Load model from checkpoint\n",
        "        model = empty_model\n",
        "        model.load_state_dict(torch.load(checkpoint, map_location=torch.device('cpu'), weights_only=False)['state_dict'])\n",
        "\n",
        "        # Get outputs and probabilities\n",
        "        output = model(torch.tensor(image_tensors))\n",
        "        probabilities = nn.Softmax(dim=1)(output) # or nn.LogSoftmax(dim=1)(output)\n",
        "        epoch = checkpoint.split('_')[-1].split('.')[0]\n",
        "        sample_ids = custom_dataset.sample_ids\n",
        "\n",
        "        for i, sample_id in enumerate(sample_ids):\n",
        "            sample = fo_dataset[sample_id]\n",
        "            for class_index in range(10):\n",
        "                sample[f\"epoch_{epoch}_class_{class_index}_prob\"] = float(probabilities[i, class_index].item())\n",
        "            sample.save()  # <-- Save each modified sample\n",
        "\n",
        "# Tag probabilities for each class\n",
        "tag_class_probabilities(checkpoints, fo_dataset, custom_fiftyone_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C3K9h0R35Ck"
      },
      "source": [
        "#### Tag loss values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TlVbVdQPOX5p"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_0.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_0.pth.tar\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_25.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_25.pth.tar\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_50.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_50.pth.tar\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_75.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_75.pth.tar\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_100.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_100.pth.tar\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_125.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_125.pth.tar\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_150.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_150.pth.tar\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_175.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_175.pth.tar\n"
          ]
        }
      ],
      "source": [
        "# Might be wrong since the torch cifar10 dataset and fiftyone cifar10 dataset might differ in the ordering which would result in incorrect tagging\n",
        "\n",
        "def tag_losses(checkpoints, dataset, dataloader):\n",
        "    for checkpoint in checkpoints:\n",
        "        model = empty_model\n",
        "        print(f\"Loading model from path: {checkpoint}\") # Added print statement\n",
        "        # Load the model state dictionary, ensuring map_location is set if needed (e.g., if trained on GPU and loading on CPU)\n",
        "        try: # Added try-except block for loading model\n",
        "            model.load_state_dict(torch.load(checkpoint, map_location=torch.device('cpu'), weights_only=False)['state_dict'])\n",
        "            print(f\"Successfully loaded model from {checkpoint}\") # Added print statement\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model from {checkpoint}: {e}\")\n",
        "            continue # Skip to the next checkpoint if loading fails\n",
        "        \n",
        "        checkpoint_num = checkpoint.split('_')[-1].split('.')[0]\n",
        "        model_name = f'model_epoch_{checkpoint_num}'\n",
        "        criterion_none = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "        losses_by_id = {}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels, sample_ids in dataloader:\n",
        "                outputs = model(inputs)\n",
        "                individual_losses = criterion_none(outputs, labels)\n",
        "\n",
        "                for i, sample_id in enumerate(sample_ids):\n",
        "                    losses_by_id[sample_id] = round(individual_losses[i].item(), 4)\n",
        "\n",
        "        # Ensure the 'losses' field exists only once\n",
        "        if not dataset.has_field(\"losses\"):\n",
        "            dataset.add_sample_field(\"losses\", fo.DictField)\n",
        "\n",
        "        for sample_id, loss in losses_by_id.items():\n",
        "            sample = dataset[sample_id]\n",
        "            if sample.losses is None:\n",
        "                sample.losses = {}\n",
        "            sample.losses[model_name] = loss\n",
        "            sample[model_name + \"_loss\"] = loss\n",
        "            sample.save()\n",
        "\n",
        "# Call the tag_data function with the dataloader, dataset, criterion, and checkpoint paths\n",
        "tag_losses(checkpoints, fo_dataset, custom_fiftyone_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXoIuIvSlKZ_"
      },
      "source": [
        "#### Tag method selected points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rNvwCPcfPNei",
        "outputId": "2a3b6145-92ce-4d6a-9309-544cb60ad3ce"
      },
      "outputs": [],
      "source": [
        "class BaseSelectionMixin:\n",
        "    \"\"\"Mixin providing the get_indices method for any selector.\"\"\"\n",
        "    def get_indicies(self, dataset, epoch, batch_size=64):\n",
        "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "        all_indexes = []\n",
        "\n",
        "        for i, datas in enumerate(data_loader):\n",
        "            inputs = datas[0]\n",
        "            targets = datas[1]\n",
        "            indexes = np.arange(len(inputs))\n",
        "\n",
        "            # Call batch selection logic\n",
        "            inputs, targets, indexes = self.before_batch(i, inputs, targets, indexes, epoch)\n",
        "            all_indexes.append(indexes)\n",
        "\n",
        "        return all_indexes\n",
        "\n",
        "\n",
        "class Uniform_Selection(BaseSelectionMixin, Uniform):\n",
        "    pass\n",
        "\n",
        "\n",
        "class DivBS_Selection(BaseSelectionMixin, DivBS):\n",
        "    pass\n",
        "\n",
        "\n",
        "class TrainLoss_Selection(BaseSelectionMixin, TrainLoss):\n",
        "    pass\n",
        "\n",
        "\n",
        "class RhoLoss_Selection(BaseSelectionMixin, RhoLoss):\n",
        "    pass\n",
        "\n",
        "class Bayesian_Selection(Bayesian):\n",
        "    def get_indicies(self, dataset, epoch):\n",
        "\n",
        "        data_loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "        all_indexes = []\n",
        "\n",
        "        for i, datas in enumerate(data_loader):\n",
        "            inputs = datas[0]\n",
        "            targets = datas[1]\n",
        "            indexes = np.arange(inputs.shape[0])\n",
        "\n",
        "            # Call batch selection logic\n",
        "            inputs, targets, indexes = self.before_batch(i, inputs, targets, indexes, epoch)\n",
        "            all_indexes.append(indexes)\n",
        "\n",
        "        return all_indexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "ND2KeCoLMXZH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cuda\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_0.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_0.pth.tar\n",
            "Creating DivBS...\n",
            "balance: False\n",
            "selecting samples for epoch 0, ratio 0.1\n",
            "Creating Uniform...\n",
            "selecting samples for epoch 0\n",
            "balance: False\n",
            "ratio: 0.1\n",
            "Creating TrainLoss...\n",
            "balance: False\n",
            "selecting samples for epoch 0, ratio 0.1\n",
            "Creating RhoLoss...\n",
            "Loading holdout model from /home/phancock/Online-Batch-Selection/exp/test_rholoss/RhoLoss/best_holdout.pth.tar\n",
            "Cached irreducible losses for 50000 samples in dataset.\n",
            "balance: False\n",
            "selecting samples for epoch 0, ratio 0.1\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_25.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_25.pth.tar\n",
            "Creating DivBS...\n",
            "balance: False\n",
            "selecting samples for epoch 25, ratio 0.1\n",
            "Creating Uniform...\n",
            "selecting samples for epoch 25\n",
            "balance: False\n",
            "ratio: 0.1\n",
            "Creating TrainLoss...\n",
            "balance: False\n",
            "selecting samples for epoch 25, ratio 0.1\n",
            "Creating RhoLoss...\n",
            "Loading holdout model from /home/phancock/Online-Batch-Selection/exp/test_rholoss/RhoLoss/best_holdout.pth.tar\n",
            "Cached irreducible losses for 50000 samples in dataset.\n",
            "balance: False\n",
            "selecting samples for epoch 25, ratio 0.1\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_50.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_50.pth.tar\n",
            "Creating DivBS...\n",
            "balance: False\n",
            "selecting samples for epoch 50, ratio 0.1\n",
            "Creating Uniform...\n",
            "selecting samples for epoch 50\n",
            "balance: False\n",
            "ratio: 0.1\n",
            "Creating TrainLoss...\n",
            "balance: False\n",
            "selecting samples for epoch 50, ratio 0.1\n",
            "Creating RhoLoss...\n",
            "Loading holdout model from /home/phancock/Online-Batch-Selection/exp/test_rholoss/RhoLoss/best_holdout.pth.tar\n",
            "Cached irreducible losses for 50000 samples in dataset.\n",
            "balance: False\n",
            "selecting samples for epoch 50, ratio 0.1\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_75.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_75.pth.tar\n",
            "Creating DivBS...\n",
            "balance: False\n",
            "selecting samples for epoch 75, ratio 0.1\n",
            "Creating Uniform...\n",
            "selecting samples for epoch 75\n",
            "balance: False\n",
            "ratio: 0.1\n",
            "Creating TrainLoss...\n",
            "balance: False\n",
            "selecting samples for epoch 75, ratio 0.1\n",
            "Creating RhoLoss...\n",
            "Loading holdout model from /home/phancock/Online-Batch-Selection/exp/test_rholoss/RhoLoss/best_holdout.pth.tar\n",
            "Cached irreducible losses for 50000 samples in dataset.\n",
            "balance: False\n",
            "selecting samples for epoch 75, ratio 0.1\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_100.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_100.pth.tar\n",
            "Creating DivBS...\n",
            "balance: False\n",
            "selecting samples for epoch 100, ratio 0.1\n",
            "Creating Uniform...\n",
            "selecting samples for epoch 100\n",
            "balance: False\n",
            "ratio: 0.1\n",
            "Creating TrainLoss...\n",
            "balance: False\n",
            "selecting samples for epoch 100, ratio 0.1\n",
            "Creating RhoLoss...\n",
            "Loading holdout model from /home/phancock/Online-Batch-Selection/exp/test_rholoss/RhoLoss/best_holdout.pth.tar\n",
            "Cached irreducible losses for 50000 samples in dataset.\n",
            "balance: False\n",
            "selecting samples for epoch 100, ratio 0.1\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_125.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_125.pth.tar\n",
            "Creating DivBS...\n",
            "balance: False\n",
            "selecting samples for epoch 125, ratio 0.1\n",
            "Creating Uniform...\n",
            "selecting samples for epoch 125\n",
            "balance: False\n",
            "ratio: 0.1\n",
            "Creating TrainLoss...\n",
            "balance: False\n",
            "selecting samples for epoch 125, ratio 0.1\n",
            "Creating RhoLoss...\n",
            "Loading holdout model from /home/phancock/Online-Batch-Selection/exp/test_rholoss/RhoLoss/best_holdout.pth.tar\n",
            "Cached irreducible losses for 50000 samples in dataset.\n",
            "balance: False\n",
            "selecting samples for epoch 125, ratio 0.1\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_150.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_150.pth.tar\n",
            "Creating DivBS...\n",
            "balance: False\n",
            "selecting samples for epoch 150, ratio 0.1\n",
            "Creating Uniform...\n",
            "selecting samples for epoch 150\n",
            "balance: False\n",
            "ratio: 0.1\n",
            "Creating TrainLoss...\n",
            "balance: False\n",
            "selecting samples for epoch 150, ratio 0.1\n",
            "Creating RhoLoss...\n",
            "Loading holdout model from /home/phancock/Online-Batch-Selection/exp/test_rholoss/RhoLoss/best_holdout.pth.tar\n",
            "Cached irreducible losses for 50000 samples in dataset.\n",
            "balance: False\n",
            "selecting samples for epoch 150, ratio 0.1\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_175.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_175.pth.tar\n",
            "Creating DivBS...\n",
            "balance: False\n",
            "selecting samples for epoch 175, ratio 0.1\n",
            "Creating Uniform...\n",
            "selecting samples for epoch 175\n",
            "balance: False\n",
            "ratio: 0.1\n",
            "Creating TrainLoss...\n",
            "balance: False\n",
            "selecting samples for epoch 175, ratio 0.1\n",
            "Creating RhoLoss...\n",
            "Loading holdout model from /home/phancock/Online-Batch-Selection/exp/test_rholoss/RhoLoss/best_holdout.pth.tar\n",
            "Cached irreducible losses for 50000 samples in dataset.\n",
            "balance: False\n",
            "selecting samples for epoch 175, ratio 0.1\n"
          ]
        }
      ],
      "source": [
        "# Set up logger\n",
        "try: # Added try-except block for setting up logger\n",
        "    logger = custom_logger(\"./exp\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    logger.info('device: ' + str(device))\n",
        "except Exception as e:\n",
        "    print(f\"Error setting up logger: {e}\")\n",
        "\n",
        "selected_points = {}\n",
        "methods = ['DivBS', 'Uniform', 'TrainLoss', 'RhoLoss'] #'Bayesian']\n",
        "\n",
        "for method in methods:\n",
        "    selected_points[method] = []\n",
        "\n",
        "selector_classes = {\n",
        "    \"DivBS\": DivBS_Selection,\n",
        "    \"Uniform\": Uniform_Selection,\n",
        "    \"TrainLoss\": TrainLoss_Selection,\n",
        "    \"RhoLoss\": RhoLoss_Selection,\n",
        "    #\"Bayesian\": Bayesian_Selection,\n",
        "}\n",
        "\n",
        "# NOTE: Can't start at checkpoint 0 because it raises an error with feature tensor becoming 0\n",
        "for checkpoint in checkpoints:\n",
        "\n",
        "    model = empty_model\n",
        "    print(f\"Loading model from path: {checkpoint}\") \n",
        "\n",
        "    try: # try-except block for loading model\n",
        "        model.load_state_dict(torch.load(checkpoint, map_location=torch.device('cpu'), weights_only=False)['state_dict'])\n",
        "        print(f\"Successfully loaded model from {checkpoint}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model from {checkpoint}: {e}\")\n",
        "        continue # Skip to the next checkpoint if loading fails\n",
        "    \n",
        "    checkpoint_num = int(checkpoint.split('_')[-1].split('.')[0])\n",
        "    # Create and run selectors\n",
        "    for method, cls in selector_classes.items():\n",
        "        selector = cls(config, logger)\n",
        "        selector.model = model\n",
        "        \n",
        "        run_indices = selector.get_indicies(custom_fiftyone_dataset, checkpoint_num)\n",
        "        selected_points[method].append(run_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "TQ4BHjFoJlh1"
      },
      "outputs": [],
      "source": [
        "def tag_selected_points(checkpoints, fo_dataset, custom_dataset, dataloader, selected_points, method_name):\n",
        "    # Iterate over each checkpoint\n",
        "    for ckpt_idx, checkpoint in enumerate(checkpoints):\n",
        "        # Added try-except block for loading model\n",
        "        \n",
        "        checkpoint_num = checkpoint.split('_')[-1].split('.')[0]\n",
        "        model_name = f'model_epoch_{checkpoint_num}'\n",
        "\n",
        "        sample_ids = custom_dataset.sample_ids\n",
        "        batch_size = dataloader.batch_size\n",
        "\n",
        "        # Get selected indices for this checkpoint\n",
        "        batches_of_selected_points = selected_points[ckpt_idx]\n",
        "\n",
        "        for i, sample_id in enumerate(sample_ids):\n",
        "            sample_batch_index = i // batch_size\n",
        "            in_batch_index = i % batch_size\n",
        "\n",
        "            # Get selected indices for this batch\n",
        "            batch_selected_points = batches_of_selected_points[sample_batch_index]\n",
        "            # Normalize to list\n",
        "            if isinstance(batch_selected_points, np.ndarray):\n",
        "                batch_selected_points = batch_selected_points.tolist()\n",
        "            elif isinstance(batch_selected_points, (np.int64, int)):\n",
        "                batch_selected_points = [int(batch_selected_points)]\n",
        "\n",
        "            # Convert to set for faster lookup\n",
        "            batch_selected_points = set(batch_selected_points)\n",
        "\n",
        "            # if sample is in the selected points for this batch, tag it as True, else False\n",
        "            selected = in_batch_index in batch_selected_points\n",
        "            sample = fo_dataset[sample_id]\n",
        "            sample[model_name + \"_\" + method_name + \"_selected\"] = selected\n",
        "            sample.save()\n",
        "\n",
        "for method in methods:\n",
        "    tag_selected_points(checkpoints, fo_dataset, custom_fiftyone_dataset, custom_fiftyone_dataloader, selected_points[method], method)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhDWWzBUb4qR"
      },
      "source": [
        "# Show Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Potential Improvements:\n",
        "* Add linked plot for even better visualization (which plots would be best for that?)\n",
        "* Find way to include Bayesian selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from fiftyone import ViewField as F\n",
        "\n",
        "# fo_dataset.compute_metadata()\n",
        "\n",
        "# # Define some interesting plots\n",
        "# plot1 = fo.NumericalHistogram(F(\"metadata.size_bytes\") / 1024, bins=50, xlabel=\"image size (KB)\")\n",
        "# plot2 = fo.NumericalHistogram(\"predictions.detections.confidence\", bins=50, range=[0, 1])\n",
        "# plot3 = fo.CategoricalHistogram(\"ground_truth.detections.label\", order=\"frequency\")\n",
        "# plot4 = fo.CategoricalHistogram(\"predictions.detections.label\", order=\"frequency\")\n",
        "\n",
        "# session = fo.launch_app(fo_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Construct a custoard of plots\n",
        "# plot = fo.ViewGrid([plot1, plot2, plot3, plot4], init_view=fo_dataset)\n",
        "# plot.show(height=720)\n",
        "\n",
        "# session.plots.attach(plot)m dashbo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "12fXOKVuog65"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"800\"\n",
              "            src=\"http://localhost:5151/?notebook=True&subscription=86817090-a0fd-49e2-953e-89a5dde72753\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x75e21046f520>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Notebook sessions cannot wait\n"
          ]
        }
      ],
      "source": [
        "session = fo.launch_app(fo_dataset)\n",
        "session.wait()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "v3rkwE7BkLSW",
        "2C3K9h0R35Ck"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "online-bs",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
