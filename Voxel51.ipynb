{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pzz0D_RZ7yA"
      },
      "source": [
        "Goal: We want to be able to visualize what points each batch selection method is choosing at each part of the training process of a model.\n",
        "\n",
        "Label each point with the following - loss value, batch #, if included in selection method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI2LQi_VOMXB"
      },
      "source": [
        "# Set Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Iw3ldY_RMdF"
      },
      "source": [
        "#### Install dependencies and load pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0_7gNm7DOK8D",
        "outputId": "de8b1ec0-be9b-477d-9e1a-97575bf1bbc7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/phancock/Online-Batch-Selection/.venv/lib/python3.10/site-packages/outdated/__init__.py:36: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import parse_version\n",
            "/home/phancock/Online-Batch-Selection/.venv/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "/home/phancock/Online-Batch-Selection/.venv/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import fiftyone.zoo as foz\n",
        "import cv2\n",
        "import numpy as np\n",
        "import fiftyone.brain as fob\n",
        "from fiftyone import ViewField as F\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import models\n",
        "import yaml\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import fiftyone as fo # Import fiftyone\n",
        "from PIL import Image # Import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import detectors\n",
        "import timm\n",
        "from methods.DivBS import DivBS\n",
        "from methods.Uniform import Uniform\n",
        "from methods.Bayesian import Bayesian\n",
        "from methods.TrainLoss import TrainLoss\n",
        "from methods.RhoLoss import RhoLoss\n",
        "from utils import custom_logger\n",
        "\n",
        "# resnet18_cifar10 = timm.create_model(\"resnet18_cifar10\", pretrained=True)\n",
        "# resnet34_cifar10 = timm.create_model(\"resnet34_cifar10\", pretrained=True)\n",
        "# resnet50_cifar10 = timm.create_model(\"resnet50_cifar10\", pretrained=True)\n",
        "# resnet34_supcon_cifar10 = timm.create_model(\"resnet34_supcon_cifar10\", pretrained=True)\n",
        "resnet50_supcon_cifar10 = timm.create_model(\"resnet50_supcon_cifar10\", pretrained=True)\n",
        "#resnet50_simclr_cifar10 = timm.create_model(\"resnet50_simclr_cifar10\", pretrained=True)\n",
        "pretrained_models = {\n",
        "    # \"resnet18_cifar10\": resnet18_cifar10,\n",
        "    # \"resnet34_cifar10\": resnet34_cifar10,\n",
        "    # \"resnet50_cifar10\": resnet50_cifar10,\n",
        "    # \"resnet34_supcon_cifar10\": resnet34_supcon_cifar10,\n",
        "    \"resnet50_supcon_cifar10\": resnet50_supcon_cifar10,\n",
        "    #\"resnet50_simclr_cifar10\": resnet50_simclr_cifar10\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G41odTNh8iqP"
      },
      "source": [
        "#### Set up consistent dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAP92qAN6GQU",
        "outputId": "f5d4557d-5891-42a9-d7b4-1105e3bea3c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split 'test' already downloaded\n",
            "Loading existing dataset 'cifar10-test'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
          ]
        }
      ],
      "source": [
        "# Define the FiftyOneCIFARDataset class (copied from cell_id: -zonHH4HkINl)\n",
        "class FiftyOneCIFARDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, fiftyone_dataset, class_to_idx, transform=None):\n",
        "        self.dataset = fiftyone_dataset\n",
        "        self.transform = transform\n",
        "        self.sample_ids = list(self.dataset.values(\"_id\"))  # List of sample IDs\n",
        "        self.class_to_idx = class_to_idx # Store the class_to_idx mapping\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sample_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample_id = self.sample_ids[idx]\n",
        "        sample = self.dataset[sample_id]  # Access by sample ID\n",
        "        img = Image.open(sample.filepath).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        # Convert string label to integer index using the mapping\n",
        "        label_str = sample.ground_truth.label\n",
        "        label_int = self.class_to_idx[label_str]\n",
        "        label_tensor = torch.tensor(label_int, dtype=torch.long) # Ensure label is a LongTensor\n",
        "\n",
        "        return img, label_tensor, str(sample_id)  # Return tensor label and sample_id as string\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Use train_dataset to get class_to_idx function\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "class_to_idx = train_dataset.class_to_idx\n",
        "\n",
        "# Instantiate the original Fiftyone dataset, custum FiftyOne dataset, and dataloader\n",
        "fo_dataset = foz.load_zoo_dataset(\"cifar10\", split=\"test\")\n",
        "custom_fiftyone_dataset = FiftyOneCIFARDataset(fo_dataset, class_to_idx=class_to_idx, transform=transform)\n",
        "custom_fiftyone_dataloader = DataLoader(custom_fiftyone_dataset, batch_size=64, shuffle=False) # Use shuffle=False for consistent batching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSdtZppARHTo"
      },
      "source": [
        "#### Set up ResNet model checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8HnVuk78RFyJ"
      },
      "outputs": [],
      "source": [
        "# Read config file\n",
        "config_file = \"cfg/cifar10.yaml\"\n",
        "with open(config_file, 'r') as f:\n",
        "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
        "        f.close()\n",
        "\n",
        "model_type = config['networks']['type']\n",
        "model_args = config['networks']['params']\n",
        "empty_model = getattr(models, model_type)(**model_args)\n",
        "\n",
        "checkpoints = ['visualization_checkpoints/checkpoint_epoch_' + str(checkpoint) + '.pth.tar' for checkpoint in [1, 9]]# range(0, 10)] # or range(0, 200, 25)\n",
        "model_params = torch.load(checkpoints[0], map_location=torch.device('cpu'), weights_only=False)\n",
        "#empty_model.load_state_dict(model_params['state_dict'])\n",
        "\n",
        "# Temporary to make everything run faster\n",
        "# first_checkpoint = checkpoints[0]\n",
        "# last_checkpoint = checkpoints[-1]\n",
        "# checkpoints = [first_checkpoint, last_checkpoint]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3rkwE7BkLSW"
      },
      "source": [
        "#### FiftyOne Analysis Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "sXUxxHnSlXlK"
      },
      "outputs": [],
      "source": [
        "def prepare_embeddings(model, model_name, fo_dataset):\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    batch_size = 128\n",
        "    embeddings = []\n",
        "\n",
        "    # Resize, normalize, and convert images to (C, H, W)\n",
        "    target_size = (32, 32)  # required input size for the CNN\n",
        "\n",
        "    image_tensors = []\n",
        "    for f in fo_dataset.values(\"filepath\"):\n",
        "        img = cv2.imread(f, cv2.IMREAD_COLOR)  # force 3-channel BGR\n",
        "        img = cv2.resize(img, target_size)\n",
        "        img = img.astype(np.float32) / 255.0  # normalize to [0,1]\n",
        "        img = img.transpose(2, 0, 1)  # convert from (H, W, C) to (C, H, W)\n",
        "        image_tensors.append(img)\n",
        "\n",
        "    for i in range(0, len(image_tensors), batch_size):\n",
        "        batch_np = np.stack(image_tensors[i:i+batch_size])\n",
        "        batch_tensor = torch.tensor(batch_np)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out = model(batch_tensor)\n",
        "            embeddings.append(out.cpu().numpy())\n",
        "\n",
        "    embedding_outputs = np.concatenate(embeddings, axis=0)\n",
        "\n",
        "    results = fob.compute_visualization(\n",
        "        fo_dataset,\n",
        "        embeddings=embedding_outputs,\n",
        "        num_dims=2,\n",
        "        method=\"umap\",\n",
        "        brain_key=model_name+\"_test\",\n",
        "        verbose=True,\n",
        "        seed=51,\n",
        "    )\n",
        "    fo_dataset.load_brain_results(model_name+\"_test\")\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating visualization...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/phancock/Online-Batch-Selection/.venv/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UMAP(n_jobs=1, random_state=51, verbose=True)\n",
            "Tue Oct 14 13:27:04 2025 Construct fuzzy simplicial set\n",
            "Tue Oct 14 13:27:04 2025 Finding Nearest Neighbors\n",
            "Tue Oct 14 13:27:04 2025 Building RP forest with 10 trees\n",
            "Tue Oct 14 13:27:10 2025 NN descent for 13 iterations\n",
            "\t 1  /  13\n",
            "\t 2  /  13\n",
            "\t 3  /  13\n",
            "\t 4  /  13\n",
            "\tStopping threshold met -- exiting after 4 iterations\n",
            "Tue Oct 14 13:27:23 2025 Finished Nearest Neighbor Search\n",
            "Tue Oct 14 13:27:25 2025 Construct embedding\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d54536730e4487a829877d9e859a760",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epochs completed:   0%|            0/500 [00:00]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tcompleted  0  /  500 epochs\n",
            "\tcompleted  50  /  500 epochs\n",
            "\tcompleted  100  /  500 epochs\n",
            "\tcompleted  150  /  500 epochs\n",
            "\tcompleted  200  /  500 epochs\n",
            "\tcompleted  250  /  500 epochs\n",
            "\tcompleted  300  /  500 epochs\n",
            "\tcompleted  350  /  500 epochs\n",
            "\tcompleted  400  /  500 epochs\n",
            "\tcompleted  450  /  500 epochs\n",
            "Tue Oct 14 13:27:37 2025 Finished embedding\n"
          ]
        }
      ],
      "source": [
        "## Optional to reset FiftyOne database\n",
        "# fo_dataset.delete()\n",
        "\n",
        "# Load embeddings for each model\n",
        "for model_name, model in pretrained_models.items():\n",
        "    prepare_embeddings(model, model_name, fo_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMXjCVba1vg6"
      },
      "source": [
        "# Add tags to dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Tag batch numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tag_batches(fo_dataset, custom_dataset, fo_dataloader):\n",
        "    if not fo_dataset.has_field(\"batch_num\"):\n",
        "        fo_dataset.add_sample_field(\"batch_num\", fo.IntField)\n",
        "\n",
        "    sample_ids = custom_dataset.sample_ids\n",
        "    batch_size = fo_dataloader.batch_size\n",
        "\n",
        "    for i, sample_id in enumerate(sample_ids):\n",
        "        batch_index = i // batch_size\n",
        "        sample = fo_dataset[sample_id]\n",
        "        sample[\"batch_num\"] = batch_index\n",
        "        sample.save()  # <-- Save each modified sample\n",
        "\n",
        "tag_batches(fo_dataset, custom_fiftyone_dataset, custom_fiftyone_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Tag class probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_287242/1136682021.py:18: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  output = model(torch.tensor(image_tensors))\n"
          ]
        }
      ],
      "source": [
        "# Tag class probabilities to each sample in the fiftyone dataset\n",
        "def tag_class_probabilities(checkpoints, fo_dataset, custom_dataset):\n",
        "    \n",
        "    image_tensors = []\n",
        "    for f in fo_dataset.values(\"filepath\"):\n",
        "        img = cv2.imread(f, cv2.IMREAD_COLOR)  # force 3-channel BGR\n",
        "        img = cv2.resize(img, (32, 32))\n",
        "        img = img.astype(np.float32) / 255.0  # normalize to [0,1]\n",
        "        img = img.transpose(2, 0, 1)  # convert from (H, W, C) to (C, H, W)\n",
        "        image_tensors.append(img)\n",
        "\n",
        "    for checkpoint in checkpoints:\n",
        "        # Load model from checkpoint\n",
        "        model = empty_model\n",
        "        model.load_state_dict(torch.load(checkpoint, map_location=torch.device('cpu'), weights_only=False)['state_dict'])\n",
        "\n",
        "        # Get outputs and probabilities\n",
        "        output = model(torch.tensor(image_tensors))\n",
        "        probabilities = nn.Softmax(dim=1)(output) # or nn.LogSoftmax(dim=1)(output)\n",
        "        epoch = checkpoint.split('_')[-1].split('.')[0]\n",
        "        sample_ids = custom_dataset.sample_ids\n",
        "\n",
        "        for i, sample_id in enumerate(sample_ids):\n",
        "            sample = fo_dataset[sample_id]\n",
        "            for class_index in range(10):\n",
        "                sample[f\"epoch_{epoch}_class_{class_index}_prob\"] = float(probabilities[i, class_index].item())\n",
        "            sample.save()  # <-- Save each modified sample\n",
        "\n",
        "# Tag probabilities for each class\n",
        "tag_class_probabilities(checkpoints, fo_dataset, custom_fiftyone_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C3K9h0R35Ck"
      },
      "source": [
        "#### Tag loss values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TlVbVdQPOX5p"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_1.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_1.pth.tar\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_9.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_9.pth.tar\n"
          ]
        }
      ],
      "source": [
        "# Might be wrong since the torch cifar10 dataset and fiftyone cifar10 dataset might differ in the ordering which would result in incorrect tagging\n",
        "\n",
        "def tag_losses(checkpoints, dataset, dataloader):\n",
        "    for checkpoint in checkpoints:\n",
        "        model = empty_model\n",
        "        print(f\"Loading model from path: {checkpoint}\") # Added print statement\n",
        "        # Load the model state dictionary, ensuring map_location is set if needed (e.g., if trained on GPU and loading on CPU)\n",
        "        try: # Added try-except block for loading model\n",
        "            model.load_state_dict(torch.load(checkpoint, map_location=torch.device('cpu'), weights_only=False)['state_dict'])\n",
        "            print(f\"Successfully loaded model from {checkpoint}\") # Added print statement\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model from {checkpoint}: {e}\")\n",
        "            continue # Skip to the next checkpoint if loading fails\n",
        "        \n",
        "        checkpoint_num = checkpoint.split('_')[-1].split('.')[0]\n",
        "        model_name = f'model_epoch_{checkpoint_num}'\n",
        "        criterion_none = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "        losses_by_id = {}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels, sample_ids in dataloader:\n",
        "                outputs = model(inputs)\n",
        "                individual_losses = criterion_none(outputs, labels)\n",
        "\n",
        "                for i, sample_id in enumerate(sample_ids):\n",
        "                    losses_by_id[sample_id] = round(individual_losses[i].item(), 4)\n",
        "\n",
        "        # Ensure the 'losses' field exists only once\n",
        "        if not dataset.has_field(\"losses\"):\n",
        "            dataset.add_sample_field(\"losses\", fo.DictField)\n",
        "\n",
        "        for sample_id, loss in losses_by_id.items():\n",
        "            sample = dataset[sample_id]\n",
        "            if sample.losses is None:\n",
        "                sample.losses = {}\n",
        "            sample.losses[model_name] = loss\n",
        "            sample[model_name + \"_loss\"] = loss\n",
        "            sample.save()\n",
        "\n",
        "# Call the tag_data function with the dataloader, dataset, criterion, and checkpoint paths\n",
        "tag_losses(checkpoints, fo_dataset, custom_fiftyone_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXoIuIvSlKZ_"
      },
      "source": [
        "#### Tag method selected points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rNvwCPcfPNei",
        "outputId": "2a3b6145-92ce-4d6a-9309-544cb60ad3ce"
      },
      "outputs": [],
      "source": [
        "class BaseSelectionMixin:\n",
        "    \"\"\"Mixin providing the get_indices method for any selector.\"\"\"\n",
        "    def get_indices(self, dataset, epoch, batch_size=64):\n",
        "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "        all_indexes = []\n",
        "\n",
        "        for i, datas in enumerate(data_loader):\n",
        "            inputs = datas[0]\n",
        "            targets = datas[1]\n",
        "            indexes = np.arange(len(inputs))\n",
        "\n",
        "            # Call batch selection logic\n",
        "            inputs, targets, indexes = self.before_batch(i, inputs, targets, indexes, epoch)\n",
        "            all_indexes.append(indexes)\n",
        "\n",
        "        return all_indexes\n",
        "\n",
        "\n",
        "class Uniform_Selection(BaseSelectionMixin, Uniform):\n",
        "    pass\n",
        "\n",
        "\n",
        "class DivBS_Selection(BaseSelectionMixin, DivBS):\n",
        "    pass\n",
        "\n",
        "\n",
        "class TrainLoss_Selection(BaseSelectionMixin, TrainLoss):\n",
        "    pass\n",
        "\n",
        "\n",
        "class RhoLoss_Selection(BaseSelectionMixin, RhoLoss):\n",
        "    pass\n",
        "\n",
        "class Bayesian_Selection(Bayesian):\n",
        "    def get_indices(self, dataset, epoch):\n",
        "\n",
        "        data_loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "        all_indexes = []\n",
        "\n",
        "        for i, datas in enumerate(data_loader):\n",
        "            inputs = datas[0]\n",
        "            targets = datas[1]\n",
        "            indexes = np.arange(inputs.shape[0])\n",
        "\n",
        "            # Call batch selection logic\n",
        "            inputs, targets, indexes = self.before_batch(i, inputs, targets, indexes, epoch)\n",
        "            all_indexes.append(indexes)\n",
        "\n",
        "        return all_indexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "ND2KeCoLMXZH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cuda\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_1.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_1.pth.tar\n",
            "Creating DivBS...\n",
            "balance: False\n",
            "selecting samples for epoch 1, ratio 0.1\n",
            "Creating Uniform...\n",
            "selecting samples for epoch 1\n",
            "balance: False\n",
            "ratio: 0.1\n",
            "Creating TrainLoss...\n",
            "balance: False\n",
            "selecting samples for epoch 1, ratio 0.1\n",
            "Creating RhoLoss...\n",
            "Loading holdout model from /home/phancock/Online-Batch-Selection/exp/example_holdout.pth.tar\n",
            "Cached irreducible losses for 50000 samples in dataset.\n",
            "balance: False\n",
            "selecting samples for epoch 1, ratio 0.1\n",
            "Loading model from path: visualization_checkpoints/checkpoint_epoch_9.pth.tar\n",
            "Successfully loaded model from visualization_checkpoints/checkpoint_epoch_9.pth.tar\n",
            "Creating DivBS...\n",
            "balance: False\n",
            "selecting samples for epoch 9, ratio 0.1\n",
            "Creating Uniform...\n",
            "selecting samples for epoch 9\n",
            "balance: False\n",
            "ratio: 0.1\n",
            "Creating TrainLoss...\n",
            "balance: False\n",
            "selecting samples for epoch 9, ratio 0.1\n",
            "Creating RhoLoss...\n",
            "Loading holdout model from /home/phancock/Online-Batch-Selection/exp/example_holdout.pth.tar\n",
            "Cached irreducible losses for 50000 samples in dataset.\n",
            "balance: False\n",
            "selecting samples for epoch 9, ratio 0.1\n"
          ]
        }
      ],
      "source": [
        "# Set up logger\n",
        "try: # Added try-except block for setting up logger\n",
        "    logger = custom_logger(\"./exp\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    logger.info('device: ' + str(device))\n",
        "except Exception as e:\n",
        "    print(f\"Error setting up logger: {e}\")\n",
        "\n",
        "selected_points = {}\n",
        "methods = ['DivBS', 'Uniform', 'TrainLoss', 'RhoLoss'] #'Bayesian']\n",
        "\n",
        "for method in methods:\n",
        "    selected_points[method] = []\n",
        "\n",
        "selector_classes = {\n",
        "    \"DivBS\": DivBS_Selection,\n",
        "    \"Uniform\": Uniform_Selection,\n",
        "    \"TrainLoss\": TrainLoss_Selection,\n",
        "    \"RhoLoss\": RhoLoss_Selection,\n",
        "    #\"Bayesian\": Bayesian_Selection,\n",
        "}\n",
        "\n",
        "# NOTE: Can't start at checkpoint 0 because it raises an error with feature tensor becoming 0\n",
        "for checkpoint in checkpoints:\n",
        "\n",
        "    model = empty_model\n",
        "    print(f\"Loading model from path: {checkpoint}\") \n",
        "\n",
        "    try: # try-except block for loading model\n",
        "        model.load_state_dict(torch.load(checkpoint, map_location=torch.device('cpu'), weights_only=False)['state_dict'])\n",
        "        print(f\"Successfully loaded model from {checkpoint}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model from {checkpoint}: {e}\")\n",
        "        continue # Skip to the next checkpoint if loading fails\n",
        "    \n",
        "    checkpoint_num = int(checkpoint.split('_')[-1].split('.')[0])\n",
        "    # Create and run selectors\n",
        "    for method, cls in selector_classes.items():\n",
        "        selector = cls(config, logger)\n",
        "        selector.model = model\n",
        "        \n",
        "        run_indices = selector.get_indices(custom_fiftyone_dataset, checkpoint_num)\n",
        "        selected_points[method].append(run_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "TQ4BHjFoJlh1"
      },
      "outputs": [],
      "source": [
        "def tag_selected_points(checkpoints, fo_dataset, custom_dataset, dataloader, selected_points, method_name):\n",
        "    # Iterate over each checkpoint\n",
        "    for ckpt_idx, checkpoint in enumerate(checkpoints):\n",
        "        # Added try-except block for loading model\n",
        "        \n",
        "        checkpoint_num = checkpoint.split('_')[-1].split('.')[0]\n",
        "        model_name = f'model_epoch_{checkpoint_num}'\n",
        "\n",
        "        sample_ids = custom_dataset.sample_ids\n",
        "        batch_size = dataloader.batch_size\n",
        "\n",
        "        # Get selected indices for this checkpoint\n",
        "        batches_of_selected_points = selected_points[ckpt_idx]\n",
        "\n",
        "        for i, sample_id in enumerate(sample_ids):\n",
        "            sample_batch_index = i // batch_size\n",
        "            in_batch_index = i % batch_size\n",
        "\n",
        "            # Get selected indices for this batch\n",
        "            batch_selected_points = batches_of_selected_points[sample_batch_index]\n",
        "            # Normalize to list\n",
        "            if isinstance(batch_selected_points, np.ndarray):\n",
        "                batch_selected_points = batch_selected_points.tolist()\n",
        "            elif isinstance(batch_selected_points, (np.int64, int)):\n",
        "                batch_selected_points = [int(batch_selected_points)]\n",
        "\n",
        "            # Convert to set for faster lookup\n",
        "            batch_selected_points = set(batch_selected_points)\n",
        "\n",
        "            # if sample is in the selected points for this batch, tag it as True, else False\n",
        "            selected = in_batch_index in batch_selected_points\n",
        "            sample = fo_dataset[sample_id]\n",
        "            sample[model_name + \"_\" + method_name + \"_selected\"] = selected\n",
        "            sample.save()\n",
        "\n",
        "for method in methods:\n",
        "    tag_selected_points(checkpoints, fo_dataset, custom_fiftyone_dataset, custom_fiftyone_dataloader, selected_points[method], method)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([7, 9, 6,  ..., 2, 7, 7])\n",
            "tensor([9, 8, 6,  ..., 5, 1, 7])\n"
          ]
        }
      ],
      "source": [
        "# label epoch predictions\n",
        "image_tensors = []\n",
        "for f in fo_dataset.values(\"filepath\"):\n",
        "    img = cv2.imread(f, cv2.IMREAD_COLOR)  # force 3-channel BGR\n",
        "    img = cv2.resize(img, (32, 32))\n",
        "    img = img.astype(np.float32) / 255.0  # normalize to [0,1]\n",
        "    img = img.transpose(2, 0, 1)  # convert from (H, W, C) to (C, H, W)\n",
        "    image_tensors.append(img)\n",
        "\n",
        "for checkpoint in checkpoints:\n",
        "    # Load model from checkpoint\n",
        "    model = empty_model\n",
        "    model.load_state_dict(torch.load(checkpoint, map_location=torch.device('cpu'), weights_only=False)['state_dict'])\n",
        "\n",
        "    # Get outputs and probabilities\n",
        "    output = model(torch.tensor(image_tensors))\n",
        "    probabilities = nn.Softmax(dim=1)(output) # or nn.LogSoftmax(dim=1)(output)\n",
        "    epoch = checkpoint.split('_')[-1].split('.')[0]\n",
        "    sample_ids = custom_fiftyone_dataset.sample_ids\n",
        "\n",
        "    print(probabilities.argmax(dim=1))\n",
        "\n",
        "    for i, sample_id in enumerate(sample_ids):\n",
        "        pred_class = int(probabilities.argmax(dim=1)[i].item())\n",
        "        sample = fo_dataset[sample_id]\n",
        "        # Store as a Classification label (which supports colors)\n",
        "        sample[f\"epoch_{epoch}_predictions\"] = fo.Classification(\n",
        "            label=str(pred_class),  # use string name or class id\n",
        "            confidence=float(probabilities[i][pred_class].item())\n",
        "        )\n",
        "        sample.save()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhDWWzBUb4qR"
      },
      "source": [
        "# Show Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from data.cifar import cifar10_classes\n",
        "\n",
        "# Shared color pool\n",
        "shared_color_pool = [\n",
        "    \"#e6194b\",  # red\n",
        "    \"#3cb44b\",  # green\n",
        "    \"#0082c8\",  # blue\n",
        "    \"#f58231\",  # orange\n",
        "    \"#911eb4\",  # purple\n",
        "    \"#46f0f0\",  # cyan\n",
        "    \"#f032e6\",  # magenta\n",
        "    \"#d2f53c\",  # lime\n",
        "    \"#fabebe\",  # pink\n",
        "    \"#008080\",  # teal\n",
        "]\n",
        "\n",
        "# Generate value-color mapping for both string labels and numeric indices\n",
        "shared_value_colors = []\n",
        "for idx, label in enumerate(cifar10_classes):\n",
        "    color = shared_color_pool[idx % len(shared_color_pool)]\n",
        "    shared_value_colors.append({\"value\": label, \"color\": color})\n",
        "    shared_value_colors.append({\"value\": idx, \"color\": color})\n",
        "\n",
        "prediction_fields = [f for f in fo_dataset.get_field_schema().keys() if \"predictions\" in f]\n",
        "\n",
        "fields_config = [\n",
        "    {\n",
        "        \"path\": \"ground_truth\",\n",
        "        \"colorByAttribute\": \"label\",\n",
        "        \"valueColors\": shared_value_colors,\n",
        "    }\n",
        "]\n",
        "\n",
        "for field in prediction_fields:\n",
        "    fields_config.append({\n",
        "        \"path\": field,\n",
        "        \"colorByAttribute\": \"label\",\n",
        "        \"valueColors\": shared_value_colors,\n",
        "    })\n",
        "\n",
        "default_mask_targets_colors = [\n",
        "    {\"intTarget\": idx, \"color\": color}\n",
        "    for idx, color in enumerate(shared_color_pool)\n",
        "]\n",
        "\n",
        "# Apply the color scheme to both ground truth and predictions\n",
        "fo_dataset.app_config.color_scheme = fo.ColorScheme(\n",
        "    color_by=\"value\",\n",
        "    color_pool=shared_color_pool,\n",
        "    fields= fields_config,\n",
        "    opacity=0.5,\n",
        "    show_skeletons=True,\n",
        "    default_mask_targets_colors = default_mask_targets_colors,\n",
        "    default_colorscale={\"name\": \"sunset\", \"list\": None},\n",
        ")\n",
        "\n",
        "# Save the configuration to the dataset\n",
        "fo_dataset.save()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.metrics import confusion_matrix\n",
        "# import fiftyone as fo\n",
        "\n",
        "# # Get true and predicted labels as lists\n",
        "# y_true = list(fo_dataset.values(\"ground_truth.label\"))\n",
        "# y_pred = list(fo_dataset.values(\"epoch_9_predictions.label\"))\n",
        "\n",
        "# # Compute confusion matrix\n",
        "# cm = confusion_matrix(y_true, y_pred)[10:, :10]\n",
        "\n",
        "# id_matrix = [[[] for _ in range(10)] for _ in range(10)]\n",
        "\n",
        "# for sample in fo_dataset:\n",
        "#     true_label = sample.ground_truth.label\n",
        "#     pred_label = sample.epoch_9_predictions.label\n",
        "#     pred = cifar10_classes[int(sample.epoch_9_predictions.label)]  # convert int -> label\n",
        "#     if true_label in cifar10_classes and pred in cifar10_classes:\n",
        "#         i = cifar10_classes.index(true_label)\n",
        "#         j = cifar10_classes.index(pred)\n",
        "#         id_matrix[i][j].append(sample.id)\n",
        "\n",
        "# print(id_matrix)\n",
        "# # Plot normalized confusion matrix\n",
        "# results = fo.core.plots.plot_confusion_matrix(\n",
        "#     cm,\n",
        "#     labels=[\n",
        "#         \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
        "#         \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
        "#     ],\n",
        "#     ids = id_matrix\n",
        "# )\n",
        "# results.show()\n",
        "\n",
        "# # Launch app\n",
        "# session = fo.launch_app(fo_dataset, browser=True, port=5151)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be681d0d749c41dfae58d1fb3cdcef5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FigureWidget({\n",
              "    'data': [{'colorbar': {'len': 1, 'lenmode': 'fraction'},\n",
              "              'colorscale': [[0.0, 'rgb(255,245,235)'], [0.125,\n",
              "                             'rgb(254,230,206)'], [0.25, 'rgb(253,208,162)'],\n",
              "                             [0.375, 'rgb(253,174,107)'], [0.5, 'rgb(253,141,60)'],\n",
              "                             [0.625, 'rgb(241,105,19)'], [0.75, 'rgb(217,72,1)'],\n",
              "                             [0.875, 'rgb(166,54,3)'], [1.0, 'rgb(127,39,4)']],\n",
              "              'hovertemplate': ('<b>count: %{z:d}</b><br>ground' ... 'ons.label: %{x}<extra></extra>'),\n",
              "              'type': 'heatmap',\n",
              "              'uid': 'bcac7142-01bd-4979-b367-380d5ca76118',\n",
              "              'x': [airplane, automobile, bird, cat, deer, dog, frog, horse, ship,\n",
              "                    truck],\n",
              "              'y': array(['truck', 'ship', 'horse', 'frog', 'dog', 'deer', 'cat', 'bird',\n",
              "                          'automobile', 'airplane'], dtype=object),\n",
              "              'z': {'bdata': ('IQAXAA4AFQABABwAIwBDABIA+AKtAA' ... 'MB2AEKALgAEQAEACEAOQAjAHMASQA='),\n",
              "                    'dtype': 'i2',\n",
              "                    'shape': '10, 10'},\n",
              "              'zmax': np.int64(760),\n",
              "              'zmin': 0}],\n",
              "    'layout': {'margin': {'b': 0, 'l': 0, 'r': 0, 't': 30},\n",
              "               'template': '...',\n",
              "               'xaxis': {'constrain': 'domain', 'range': [-0.5, 9.5]},\n",
              "               'yaxis': {'constrain': 'domain', 'range': [-0.5, 9.5], 'scaleanchor': 'x', 'scaleratio': 1}}\n",
              "})"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"800\"\n",
              "            src=\"http://localhost:5151/?notebook=True&subscription=61dde457-8c63-4a64-ab71-0ceb0928639c\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x707c5acc3250>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import fiftyone as fo\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Define label order\n",
        "labels = [\n",
        "    \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
        "    \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
        "]\n",
        "\n",
        "# Ensure consistent field values\n",
        "y_true = list(fo_dataset.values(\"ground_truth.label\"))\n",
        "y_pred = list(fo_dataset.values(\"epoch_9_predictions.label\"))\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)[10:, :10]\n",
        "\n",
        "# Filter to only samples that have both labels\n",
        "sample_ids = []\n",
        "for s in fo_dataset:\n",
        "    if s.ground_truth is None or s.epoch_9_predictions is None:\n",
        "        continue\n",
        "    sample_ids.append(s.id)\n",
        "view = fo_dataset.select(sample_ids)\n",
        "\n",
        "# --- âœ… Interactive confusion matrix ---\n",
        "from fiftyone.core.plots import plot_confusion_matrix\n",
        "\n",
        "cm_plot = plot_confusion_matrix(\n",
        "    cm,\n",
        "    labels=labels,\n",
        "    samples=view,                      \n",
        "    gt_field=\"ground_truth.label\",\n",
        "    pred_field=\"epoch_9_predictions.label\",\n",
        "    backend=\"plotly\",\n",
        ")\n",
        "\n",
        "cm_plot.show()\n",
        "session = fo.launch_app(fo_dataset)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "v3rkwE7BkLSW",
        "2C3K9h0R35Ck"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "online-bs",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}